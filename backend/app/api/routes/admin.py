from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from sqlalchemy import func, and_, or_, String, text
from typing import List, Optional
import logging

from app.database import get_db
from app.models.user import User
from app.models.queue import QueueEntry, QueueStatus
from app.models.video import VideoSettings
from app.schemas.queue import QueueResponse
from app.schemas.video import VideoSettingsResponse, VideoSettingsUpdate
from app.schemas import AdminUserCreate, UserResponse, UserUpdate
from app.security import get_admin_user
from app.services.user import create_user
from app.services.queue import get_all_queue_entries
from app.services.archive import get_archive_statistics, cleanup_old_completed_entries, archive_queue_entry
from app.models.archive import ArchivedQueueEntry
from fastapi.responses import StreamingResponse
import io
import csv
from openpyxl import Workbook 
from openpyxl.styles import Font, PatternFill, Alignment

router = APIRouter()
logger = logging.getLogger(__name__)

# –ü–æ–ª–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–æ–≥—Ä–∞–º–º –Ω–∞ –∫–æ–¥—ã
PROGRAM_MAPPING = {
    # –ë–ê–ö–ê–õ–ê–í–†–ò–ê–¢
    # –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    "–±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏–π —É—á—ë—Ç": "accounting",
    "–±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏–π —É—á–µ—Ç": "accounting",
    "–ø—Ä–∏–∫–ª–∞–¥–Ω–∞—è –ª–∏–Ω–≥–≤–∏—Å—Ç–∏–∫–∞": "appliedLinguistics",
    "—ç–∫–æ–Ω–æ–º–∏–∫–∞ –∏ –Ω–∞—É–∫–∞ –æ –¥–∞–Ω–Ω—ã—Ö": "economicsDataScience",
    "—Ñ–∏–Ω–∞–Ω—Å—ã": "finance",
    "–≥–æ—Å—Ç–µ–ø—Ä–∏–∏–º—Å—Ç–≤–æ": "hospitality",
    "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è –∂—É—Ä–Ω–∞–ª–∏—Å—Ç–∏–∫–∞": "internationalJournalism",
    "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–µ –ø—Ä–∞–≤–æ": "internationalLaw",
    "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è": "internationalRelations",
    "it": "it",
    "–∏—Ç": "it",
    "—é—Ä–∏—Å–ø—Ä—É–¥–µ–Ω—Ü–∏—è": "jurisprudence",
    "–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç": "management",
    "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥": "marketing",
    "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è": "psychology",
    "—Ç—É—Ä–∏–∑–º": "tourism",
    "–ø–µ—Ä–µ–≤–æ–¥—á–µ—Å–∫–æ–µ –¥–µ–ª–æ": "translation",
    
    # –ö–∞–∑–∞—Ö—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    "–±—É—Ö–≥–∞–ª—Ç–µ—Ä–ª—ñ–∫ –µ—Å–µ–ø": "accounting",
    "“õ–æ–ª–¥–∞–Ω–±–∞–ª—ã –ª–∏–Ω–≥–≤–∏—Å—Ç–∏–∫–∞": "appliedLinguistics",
    "—ç–∫–æ–Ω–æ–º–∏–∫–∞ –∂”ô–Ω–µ –¥–µ—Ä–µ–∫—Ç–µ—Ä “ì—ã–ª—ã–º—ã": "economicsDataScience",
    "“õ–∞—Ä–∂—ã": "finance",
    "“õ–æ–Ω–∞“õ–∂–∞–π–ª—ã–ª—ã“õ": "hospitality",
    "—Ö–∞–ª—ã“õ–∞—Ä–∞–ª—ã“õ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç–∏–∫–∞": "internationalJournalism",
    "—Ö–∞–ª—ã“õ–∞—Ä–∞–ª—ã“õ “õ“±“õ—ã“õ": "internationalLaw",
    "—Ö–∞–ª—ã“õ–∞—Ä–∞–ª—ã“õ “õ–∞—Ç—ã–Ω–∞—Å—Ç–∞—Ä": "internationalRelations",
    "“õ“±“õ—ã“õ—Ç–∞–Ω—É": "jurisprudence",
    "–∞—É–¥–∞—Ä–º–∞ —ñ—Å—ñ": "translation",
    
    # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    "accounting": "accounting",
    "applied linguistics": "appliedLinguistics",
    "economics and data science": "economicsDataScience",
    "finance": "finance",
    "hospitality": "hospitality",
    "international journalism": "internationalJournalism",
    "international law": "internationalLaw",
    "international relations": "internationalRelations",
    "law": "jurisprudence",
    "management": "management",
    "marketing": "marketing",
    "psychology": "psychology",
    "tourism": "tourism",
    "translation studies": "translation",
    
    # –ú–ê–ì–ò–°–¢–†–ê–¢–£–†–ê
    # –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    "–ø–æ–ª–∏—Ç–æ–ª–æ–≥–∏—è –∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è": "politicalInternationalRelations",
    "–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–µ –ø—Ä–∞–≤–æ": "competitionLaw",
    "–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ç–∏–≤–Ω–∞—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è": "consultingPsychology",
    "—ç–∫–æ–Ω–æ–º–∏–∫–∞": "economics",
    "–ø—Ä–∞–≤–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –±–∏–∑–Ω–µ—Å–∞": "intellectualPropertyLaw",
    "–ø—Ä–∞–≤–æ it": "itLaw",
    "–ø—Ä–∞–≤–æ –∏—Ç": "itLaw",
    
    # –ö–∞–∑–∞—Ö—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    "—Å–∞—è—Å–∞—Ç—Ç–∞–Ω—É –∂”ô–Ω–µ —Ö–∞–ª—ã“õ–∞—Ä–∞–ª—ã“õ “õ–∞—Ç—ã–Ω–∞—Å—Ç–∞—Ä": "politicalInternationalRelations",
    "–±”ô—Å–µ–∫–µ–ª–µ—Å—Ç—ñ–∫ “õ“±“õ—ã“õ": "competitionLaw",
    "–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ç–∏–≤—Ç—ñ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è": "consultingPsychology",
    "–∑–∏—è—Ç–∫–µ—Ä–ª—ñ–∫ –º–µ–Ω—à—ñ–∫ –∂”ô–Ω–µ –±–∏–∑–Ω–µ—Å “õ“±“õ—ã“õ": "intellectualPropertyLaw",
    "“õ“±“õ—ã“õ it": "itLaw",
    
    # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    "political science and international relations": "politicalInternationalRelations",
    "competition law": "competitionLaw",
    "counselling psychology": "consultingPsychology",
    "economics": "economics",
    "intellectual property and business law": "intellectualPropertyLaw",
    "it law": "itLaw",
    
    # –î–û–ö–¢–û–†–ê–ù–¢–£–†–ê
    # –†—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    "–ø—Ä–∞–≤–æ": "law",
    "phd –ø–æ —ç–∫–æ–Ω–æ–º–∏–∫–µ": "phdEconomics",
    
    # –ö–∞–∑–∞—Ö—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    "“õ“±“õ—ã“õ": "law",
    "—ç–∫–æ–Ω–æ–º–∏–∫–∞ —Å–∞–ª–∞—Å—ã–Ω–¥–∞“ì—ã phd": "phdEconomics",
    
    # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
    "phd in law": "law",
    "phd in economics": "phdEconomics"
}

@router.post("/sync/google-sheets/full")
def full_sync_to_google_sheets(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """–ü–æ–ª–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∞—Ä—Ö–∏–≤–∞ –≤ Google Sheets"""
    try:
        from app.services.google_sheets import google_sheets_service
        
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å Google Sheets...")
        
        result = google_sheets_service.sync_all_data(db)
        
        if result.get("success"):
            logger.info(f"‚úÖ –ü–æ–ª–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return {
                "success": True,
                "message": "Full synchronization completed successfully",
                "details": result
            }
        else:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {result.get('error')}")
            return {
                "success": False,
                "message": "Full synchronization failed",
                "error": result.get("error")
            }
            
    except Exception as e:
        logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –ø–æ–ª–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=f"Full sync failed: {str(e)}")

@router.get("/sync/test-now")
def test_sync_now(db: Session = Depends(get_db)):
    """–í—Ä–µ–º–µ–Ω–Ω—ã–π —Ä–æ—É—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏"""
    try:
        from app.services.google_sheets import google_sheets_service
        result = google_sheets_service.sync_all_data(db)
        return result
    except Exception as e:
        return {"error": str(e)}

@router.get("/sync/google-sheets/status")
def get_sync_status(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å Google Sheets"""
    try:
        from app.services.scheduler import realtime_sync
        from app.services.google_sheets import google_sheets_service
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Google Sheets API
        is_available = google_sheets_service._is_available()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –∞—Ä—Ö–∏–≤–∞
        total_archive_entries = db.query(ArchivedQueueEntry).count()
        
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ Google Sheets
        sheets_rows = 0
        sheets_error = None
        
        if is_available:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞
                range_name = f'{google_sheets_service.sheet_name}!A:A'
                result = google_sheets_service.service.spreadsheets().values().get(
                    spreadsheetId=google_sheets_service.spreadsheet_id,
                    range=range_name
                ).execute()
                
                values = result.get('values', [])
                sheets_rows = len(values) - 1 if values else 0  # -1 –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
                
            except Exception as e:
                sheets_error = str(e)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        sync_stats = realtime_sync.get_sync_stats()
        
        return {
            "success": True,
            "google_sheets_available": is_available,
            "total_archive_entries": total_archive_entries,
            "google_sheets_rows": sheets_rows,
            "sheets_error": sheets_error,
            "sync_stats": sync_stats,
            "needs_full_sync": sheets_rows < total_archive_entries
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=f"Status check failed: {str(e)}")

@router.post("/sync/google-sheets/test")
def test_google_sheets_connection(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Google Sheets"""
    try:
        from app.services.google_sheets import google_sheets_service
        
        if not google_sheets_service._is_available():
            return {
                "success": False,
                "message": "Google Sheets API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
            }
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_data = [["Test", "Data", "Connection", datetime.now().isoformat()]]
        
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
            append_request = google_sheets_service.service.spreadsheets().values().append(
                spreadsheetId=google_sheets_service.spreadsheet_id,
                range=google_sheets_service.sheet_name,
                valueInputOption='RAW',
                insertDataOption='INSERT_ROWS',
                body={'values': test_data}
            )
            
            result = append_request.execute()
            
            return {
                "success": True,
                "message": "Google Sheets connection successful",
                "sheet_name": google_sheets_service.sheet_name,
                "spreadsheet_id": google_sheets_service.spreadsheet_id,
                "test_result": result.get('updates', {})
            }
            
        except Exception as e:
            return {
                "success": False,
                "message": f"Google Sheets write test failed: {str(e)}"
            }
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Google Sheets: {e}")
        raise HTTPException(status_code=500, detail=f"Test failed: {str(e)}")

def get_program_codes_by_name(program_name: str) -> List[str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–æ–¥—ã –ø—Ä–æ–≥—Ä–∞–º–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –ø—Ä–æ–≥—Ä–∞–º–º—ã
    """
    if not program_name:
        return []
    
    program_name_lower = program_name.lower().strip()
    matching_codes = []
    
    # –ò—â–µ–º —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    if program_name_lower in PROGRAM_MAPPING:
        matching_codes.append(PROGRAM_MAPPING[program_name_lower])
    
    # –ò—â–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö
    for name, code in PROGRAM_MAPPING.items():
        if program_name_lower in name or name in program_name_lower:
            if code not in matching_codes:
                matching_codes.append(code)
    
    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–º–æ–∂–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–µ–ª –∫–æ–¥ –Ω–∞–ø—Ä—è–º—É—é
    if not matching_codes:
        matching_codes.append(program_name_lower)
    
    return matching_codes

@router.get("/queue/export")
def export_queue_to_excel(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """Export all queue entries to Excel (.xlsx)"""
    # Get all queue entries
    queue_entries = get_all_queue_entries(db)
    
    # Create Excel workbook
    wb = Workbook()
    ws = wb.active
    ws.title = "Queue Data"
    
    # Headers
    headers = ["–§–ò–û", "–ü—Ä–æ–≥—Ä–∞–º–º—ã", "–ù–æ–º–µ—Ä", "–°–æ—Ç—Ä—É–¥–Ω–∏–∫", "–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è", "–°—Ç–∞—Ç—É—Å", "–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Å–µ–∫)"]
    
    # Add headers to worksheet
    for col, header in enumerate(headers, 1):
        cell = ws.cell(row=1, column=col, value=header)
        # Style headers
        cell.font = Font(bold=True, color="FFFFFF")
        cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        cell.alignment = Alignment(horizontal="center")
    
    # Add data rows
    for row, entry in enumerate(queue_entries, 2):
        programs = ", ".join(entry.programs) if isinstance(entry.programs, list) else entry.programs
        created_at = entry.created_at.strftime("%Y-%m-%d %H:%M:%S") if entry.created_at else "-"
        
        data_row = [
            entry.full_name,
            programs,
            entry.queue_number,
            entry.assigned_employee_name or "-",
            created_at,
            entry.status.value,
            entry.processing_time or "-"
        ]
        
        for col, value in enumerate(data_row, 1):
            ws.cell(row=row, column=col, value=value)
    
    # Auto-adjust column widths
    for column in ws.columns:
        max_length = 0
        column_letter = column[0].column_letter
        for cell in column:
            try:
                if len(str(cell.value)) > max_length:
                    max_length = len(str(cell.value))
            except:
                pass
        adjusted_width = min(max_length + 2, 50)
        ws.column_dimensions[column_letter].width = adjusted_width
    
    # Save to BytesIO
    output = io.BytesIO()
    wb.save(output)
    output.seek(0)
    
    # Return file as response
    headers = {
        'Content-Disposition': 'attachment; filename="queue_data.xlsx"'
    }
    return StreamingResponse(
        io.BytesIO(output.getvalue()), 
        headers=headers, 
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

@router.post("/queue/reset-numbering")
def reset_queue_numbering(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """–°–±—Ä–æ—Å–∏—Ç—å –Ω—É–º–µ—Ä–∞—Ü–∏—é –æ—á–µ—Ä–µ–¥–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∞–¥–º–∏–Ω–æ–≤)"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞—è–≤–∫–∏ (–Ω–µ completed)
        active_entries = db.query(QueueEntry).filter(
            QueueEntry.status.in_([QueueStatus.WAITING, QueueStatus.IN_PROGRESS, QueueStatus.PAUSED])
        ).order_by(QueueEntry.created_at).all()
        
        # –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º –∏ —É–¥–∞–ª—è–µ–º –≤—Å–µ completed –∑–∞—è–≤–∫–∏
        completed_entries = db.query(QueueEntry).filter(QueueEntry.status == QueueStatus.COMPLETED).all()
        
        archived_count = 0
        for entry in completed_entries:
            try:
                archive_queue_entry(db, entry, reason="manual_reset")
                db.delete(entry)
                archived_count += 1
            except Exception as e:
                continue
        
        # –ü–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤—ã–≤–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞—è–≤–∫–∏ –Ω–∞—á–∏–Ω–∞—è —Å 1
        renumbered_count = 0
        for i, entry in enumerate(active_entries, 1):
            entry.queue_number = i
            db.add(entry)
            renumbered_count += 1
        
        db.commit()
        
        return {
            "success": True,
            "message": f"Queue numbering reset successfully",
            "archived_completed": archived_count,
            "renumbered_active": renumbered_count,
            "next_number": len(active_entries) + 1
        }
        
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"Reset failed: {str(e)}")

@router.post("/create-admission", response_model=UserResponse)
def create_admission_staff(
    user_data: AdminUserCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """Create a new admission staff member (admin only)"""
    # Create a new user with admission role
    return create_user(db=db, user=user_data, role="admission")

@router.get("/employees", response_model=List[UserResponse])
def get_all_employees(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """Get all employees (admin only)"""
    employees = db.query(User).filter(User.role == "admission").all()
    return employees

@router.get("/queue", response_model=List[QueueResponse])
def get_all_queue_entries_api(
    status: Optional[QueueStatus] = None,
    date: Optional[str] = None,
    employee: Optional[str] = None,
    full_name: Optional[str] = None,
    program: Optional[str] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """Get all queue entries with filters (admin only)"""
    from datetime import datetime
    
    # –ù–∞—á–∏–Ω–∞–µ–º —Å –±–∞–∑–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    query = db.query(QueueEntry)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
    if status:
        query = query.filter(QueueEntry.status == status)
    
    if date:
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (—Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD)
        try:
            filter_date = datetime.strptime(date, "%Y-%m-%d")
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–ø–∏—Å–∏ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –≤ —ç—Ç–æ—Ç –¥–µ–Ω—å
            start_of_day = filter_date.replace(hour=0, minute=0, second=0, microsecond=0)
            end_of_day = filter_date.replace(hour=23, minute=59, second=59, microsecond=999999)
            
            query = query.filter(
                and_(
                    QueueEntry.created_at >= start_of_day,
                    QueueEntry.created_at <= end_of_day
                )
            )
        except ValueError:
            # –ï—Å–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä
            pass
    
    if employee:
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –±–µ–∑ —É—á–µ—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
        query = query.filter(
            QueueEntry.assigned_employee_name.ilike(f"%{employee}%")
        )
    
    if full_name:
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –§–ò–û –∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç–∞ (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –±–µ–∑ —É—á–µ—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
        query = query.filter(
            QueueEntry.full_name.ilike(f"%{full_name}%")
        )
    
    if program:
        # –ü–æ–ª—É—á–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–æ–¥—ã –ø—Ä–æ–≥—Ä–∞–º–º –ø–æ –≤–≤–µ–¥–µ–Ω–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é
        program_codes = get_program_codes_by_name(program)
        
        if program_codes:
            # –°–æ–∑–¥–∞–µ–º —É—Å–ª–æ–≤–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—Å–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–º –∫–æ–¥–∞–º
            program_conditions = []
            for code in program_codes:
                # –ò—â–µ–º –∫–æ–¥ –≤ JSON –º–∞—Å—Å–∏–≤–µ –ø—Ä–æ–≥—Ä–∞–º–º
                program_conditions.append(
                    text("programs::text ILIKE :code").params(code=f'%"{code}"%')
                )
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —É—Å–ª–æ–≤–∏—è —á–µ—Ä–µ–∑ OR
            if len(program_conditions) == 1:
                query = query.filter(program_conditions[0])
            else:
                query = query.filter(or_(*program_conditions))
    
    return query.all()

@router.delete("/employees/{user_id}")
def delete_employee(
    user_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """Delete employee (admin only)"""
    employee = db.query(User).filter(User.id == user_id).first()
    if not employee:
        raise HTTPException(status_code=404, detail="Employee not found")
    
    db.delete(employee)
    db.commit()
    return {"detail": "Employee deleted successfully"}

@router.put("/employees/{user_id}", response_model=UserResponse)
def update_employee(
    user_id: str,
    user_data: UserUpdate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """Update employee data (admin only)"""
    employee = db.query(User).filter(User.id == user_id).first()
    if not employee:
        raise HTTPException(status_code=404, detail="Employee not found")
    
    for key, value in user_data.dict(exclude_unset=True).items():
        setattr(employee, key, value)
    
    db.commit()
    db.refresh(employee)
    return employee

# === –ù–û–í–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –£–î–ê–õ–ï–ù–ò–Ø –ó–ê–ü–ò–°–ï–ô ===

@router.delete("/queue/{queue_id}")
def delete_queue_entry_admin(
    queue_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """–£–¥–∞–ª–∏—Ç—å –∑–∞—è–≤–∫—É –∏–∑ –æ—á–µ—Ä–µ–¥–∏ (–∞–¥–º–∏–Ω) —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π"""
    try:
        # –ò—â–µ–º –∑–∞–ø–∏—Å—å –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ
        queue_entry = db.query(QueueEntry).filter(QueueEntry.id == queue_id).first()
        
        if queue_entry:
            # –£–¥–∞–ª—è–µ–º –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
            db.delete(queue_entry)
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –∑–∞–ø–∏—Å—å {queue_id} –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –æ—á–µ—Ä–µ–¥–∏")
        
        # –ò—â–µ–º –∑–∞–ø–∏—Å—å –≤ –∞—Ä—Ö–∏–≤–µ
        archived_entry = db.query(ArchivedQueueEntry).filter(
            or_(
                ArchivedQueueEntry.id == queue_id,
                ArchivedQueueEntry.original_id == queue_id
            )
        ).first()
        
        if archived_entry:
            # üî• –í–ê–ñ–ù–û: –£–¥–∞–ª—è–µ–º –∏–∑ –∞—Ä—Ö–∏–≤–∞ - —ç—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å—Ç–∏—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é —Å Google Sheets
            db.delete(archived_entry)
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –∑–∞–ø–∏—Å—å {queue_id} –∏–∑ –∞—Ä—Ö–∏–≤–∞")
        
        if not queue_entry and not archived_entry:
            raise HTTPException(status_code=404, detail="Queue entry not found")
        
        db.commit()
        
        return {
            "success": True,
            "message": "Queue entry deleted successfully",
            "deleted_from_queue": bool(queue_entry),
            "deleted_from_archive": bool(archived_entry)
        }
        
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∑–∞—è–≤–∫–∏ {queue_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Error deleting queue entry: {str(e)}")

@router.post("/queue/bulk-delete")
def bulk_delete_queue_entries(
    entry_ids: List[str],
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """–ú–∞—Å—Å–æ–≤–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –∑–∞—è–≤–æ–∫ —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π"""
    try:
        deleted_queue = 0
        deleted_archive = 0
        
        for queue_id in entry_ids:
            # –£–¥–∞–ª—è–µ–º –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
            queue_entry = db.query(QueueEntry).filter(QueueEntry.id == queue_id).first()
            if queue_entry:
                db.delete(queue_entry)
                deleted_queue += 1
            
            # –£–¥–∞–ª—è–µ–º –∏–∑ –∞—Ä—Ö–∏–≤–∞ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç—Å—è —Å Google Sheets)
            archived_entry = db.query(ArchivedQueueEntry).filter(
                or_(
                    ArchivedQueueEntry.id == queue_id,
                    ArchivedQueueEntry.original_id == queue_id
                )
            ).first()
            if archived_entry:
                db.delete(archived_entry)
                deleted_archive += 1
        
        db.commit()
        
        return {
            "success": True,
            "message": f"Bulk delete completed",
            "deleted_from_queue": deleted_queue,
            "deleted_from_archive": deleted_archive,
            "total_processed": len(entry_ids)
        }
        
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–∞—Å—Å–æ–≤–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è: {e}")
        raise HTTPException(status_code=500, detail=f"Error bulk deleting: {str(e)}")

@router.post("/archive/cleanup")
def cleanup_archive(
    days_old: int = 30,
    status_filter: Optional[str] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """–û—á–∏—Å—Ç–∫–∞ –∞—Ä—Ö–∏–≤–∞ (—É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π) —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π"""
    try:
        from datetime import datetime, timedelta
        
        cutoff_date = datetime.utcnow() - timedelta(days=days_old)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
        query = db.query(ArchivedQueueEntry).filter(
            ArchivedQueueEntry.archived_at < cutoff_date
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ç–∞—Ç—É—Å—É –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if status_filter:
            query = query.filter(ArchivedQueueEntry.status == status_filter)
        
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å–∏ –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞
        old_entries = query.all()
        entries_count = len(old_entries)
        
        if entries_count == 0:
            return {
                "success": True,
                "message": "No entries found for cleanup",
                "deleted_count": 0,
                "cutoff_date": cutoff_date.isoformat()
            }
        
        # –£–¥–∞–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (–∫–∞–∂–¥–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª–∏—Ç—Å—è –∏–∑ Google Sheets)
        for entry in old_entries:
            db.delete(entry)
            logger.info(f"üóëÔ∏è –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –∑–∞–ø–∏—Å—å {entry.id} –∏–∑ –∞—Ä—Ö–∏–≤–∞ (–¥–∞—Ç–∞: {entry.archived_at})")
        
        db.commit()
        
        logger.info(f"‚úÖ –û—á–∏—Å—Ç–∫–∞ –∞—Ä—Ö–∏–≤–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: —É–¥–∞–ª–µ–Ω–æ {entries_count} –∑–∞–ø–∏—Å–µ–π —Å—Ç–∞—Ä—à–µ {days_old} –¥–Ω–µ–π")
        
        return {
            "success": True,
            "message": f"Archive cleanup completed",
            "deleted_count": entries_count,
            "cutoff_date": cutoff_date.isoformat(),
            "days_old": days_old,
            "status_filter": status_filter
        }
        
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∞—Ä—Ö–∏–≤–∞: {e}")
        raise HTTPException(status_code=500, detail=f"Error cleaning up archive: {str(e)}")

@router.delete("/archive/{entry_id}")
def delete_archive_entry(
    entry_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """–£–¥–∞–ª–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∑–∞–ø–∏—Å—å –∏–∑ –∞—Ä—Ö–∏–≤–∞ —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π"""
    try:
        # –ò—â–µ–º –∑–∞–ø–∏—Å—å –≤ –∞—Ä—Ö–∏–≤–µ
        archived_entry = db.query(ArchivedQueueEntry).filter(
            or_(
                ArchivedQueueEntry.id == entry_id,
                ArchivedQueueEntry.original_id == entry_id
            )
        ).first()
        
        if not archived_entry:
            raise HTTPException(status_code=404, detail="Archive entry not found")
        
        # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å—å (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ—Ç—Å—è —Å Google Sheets)
        db.delete(archived_entry)
        db.commit()
        
        logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –∑–∞–ø–∏—Å—å {entry_id} –∏–∑ –∞—Ä—Ö–∏–≤–∞")
        
        return {
            "success": True,
            "message": "Archive entry deleted successfully",
            "entry_id": entry_id
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∑–∞–ø–∏—Å–∏ –∏–∑ –∞—Ä—Ö–∏–≤–∞ {entry_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Error deleting archive entry: {str(e)}")

@router.post("/archive/bulk-delete")
def bulk_delete_archive_entries(
    entry_ids: List[str],
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """–ú–∞—Å—Å–æ–≤–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –∏–∑ –∞—Ä—Ö–∏–≤–∞ —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π"""
    try:
        deleted_count = 0
        not_found_count = 0
        
        for entry_id in entry_ids:
            # –ò—â–µ–º –∑–∞–ø–∏—Å—å –≤ –∞—Ä—Ö–∏–≤–µ
            archived_entry = db.query(ArchivedQueueEntry).filter(
                or_(
                    ArchivedQueueEntry.id == entry_id,
                    ArchivedQueueEntry.original_id == entry_id
                )
            ).first()
            
            if archived_entry:
                db.delete(archived_entry)
                deleted_count += 1
                logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –∑–∞–ø–∏—Å—å {entry_id} –∏–∑ –∞—Ä—Ö–∏–≤–∞")
            else:
                not_found_count += 1
                logger.warning(f"‚ö†Ô∏è –ó–∞–ø–∏—Å—å {entry_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –∞—Ä—Ö–∏–≤–µ")
        
        db.commit()
        
        return {
            "success": True,
            "message": f"Bulk archive delete completed",
            "deleted_count": deleted_count,
            "not_found_count": not_found_count,
            "total_processed": len(entry_ids)
        }
        
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–∞—Å—Å–æ–≤–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ –∞—Ä—Ö–∏–≤–∞: {e}")
        raise HTTPException(status_code=500, detail=f"Error bulk deleting from archive: {str(e)}")

@router.get("/archive/cleanup/preview")
def preview_archive_cleanup(
    days_old: int = 30,
    status_filter: Optional[str] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∞—Ä—Ö–∏–≤–∞"""
    try:
        from datetime import datetime, timedelta
        
        cutoff_date = datetime.utcnow() - timedelta(days=days_old)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
        query = db.query(ArchivedQueueEntry).filter(
            ArchivedQueueEntry.archived_at < cutoff_date
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ç–∞—Ç—É—Å—É –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if status_filter:
            query = query.filter(ArchivedQueueEntry.status == status_filter)
        
        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å–∏
        old_entries = query.limit(100).all()  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
        total_count = query.count()
        
        preview_entries = []
        for entry in old_entries:
            preview_entries.append({
                "id": entry.id,
                "original_id": entry.original_id,
                "full_name": entry.full_name,
                "status": entry.status.value if entry.status else None,
                "archived_at": entry.archived_at.isoformat() if entry.archived_at else None,
                "archive_reason": entry.archive_reason
            })
        
        return {
            "success": True,
            "total_entries_to_delete": total_count,
            "preview_entries": preview_entries,
            "cutoff_date": cutoff_date.isoformat(),
            "days_old": days_old,
            "status_filter": status_filter,
            "preview_limit": len(preview_entries)
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –æ—á–∏—Å—Ç–∫–∏: {e}")
        raise HTTPException(status_code=500, detail=f"Error previewing cleanup: {str(e)}")

# === –†–û–£–¢–´ –î–õ–Ø –£–ü–†–ê–í–õ–ï–ù–ò–Ø –í–ò–î–ï–û ===

@router.get("/video-settings", response_model=VideoSettingsResponse)
def get_video_settings(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """Get current video settings (admin only)"""
    settings = db.query(VideoSettings).first()
    if not settings:
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        settings = VideoSettings(youtube_url="", is_enabled=False)
        db.add(settings)
        db.commit()
        db.refresh(settings)
    return settings

@router.put("/video-settings", response_model=VideoSettingsResponse)
def update_video_settings(
    video_data: VideoSettingsUpdate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_admin_user)
):
    """Update video settings (admin only)"""
    settings = db.query(VideoSettings).first()
    if not settings:
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        settings = VideoSettings()
        db.add(settings)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è
    for key, value in video_data.dict(exclude_unset=True).items():
        setattr(settings, key, value)
    
    db.commit()
    db.refresh(settings)
    return settings